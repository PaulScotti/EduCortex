{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend using the EduCortex web viewer (http://paulscotti.com/educortex) rather than creating a local server if you simply wish to try out the tool or to use it for educational purposes. We provide the below code in case you want to understand how EduCortex was created or if you want to contribute to this project.\n",
    "\n",
    "We use Pycortex as the base for our 3D viewer, where we overlay maps on a fsaverage surface from Freesurfer. See https://github.com/gallantlab/pycortex for more information on Pycortex. We added some extra buttons and menus to the viewer using HTML/CSS/JavaScript, which are contained in the my_template.html and index.html files.\n",
    "\n",
    "We use the Neurosynth Python package as the source of our data (i.e., we import meta-analysis maps from Neurosynth). See https://github.com/neurosynth/neurosynth or https://neurosynth.org/ for more information on Neurosynth. \n",
    "\n",
    "Below we detail the following steps:\n",
    "\n",
    "° initialize Pycortex with the fsaverage brain, using my_template.html as a web template  \n",
    "\n",
    "° load PCA components across all meta-analysis maps (see PCA/PCA_extraction.ipynb for how components were created) and then overlay the top components on fsaverage \n",
    "\n",
    "° create png files for every term's meta-analysis map on Neurosynth, which can then be loaded onto the fsaverage brain in the viewer\n",
    "\n",
    "° weight each term with each PCA component to construct the PCA wordcloud used in EduCortex  \n",
    "\n",
    "° load Glasser atlas (Glasser et al., 2016) annotation files to overlay anatomical labels on the brain\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale, MinMaxScaler # to scale PCA scores to be between 0 and 255, for visualization\n",
    "import cortex\n",
    "from cortex.webgl.data import Package\n",
    "from neurosynth import meta, decode, network, Dataset\n",
    "import nibabel as nib\n",
    "from scipy import spatial # to extract the convex hull\n",
    "import pickle\n",
    "def pickle_dump(obj, file_path):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        return pickle.dump(obj, MacOSFile(f), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "def pickle_load(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(MacOSFile(f))\n",
    "class MacOSFile(object):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self.f, item)\n",
    "    def read(self, n):\n",
    "        # print(\"reading total_bytes=%s\" % n, flush=True)\n",
    "        if n >= (1 << 31):\n",
    "            buffer = bytearray(n)\n",
    "            idx = 0\n",
    "            while idx < n:\n",
    "                batch_size = min(n - idx, 1 << 31 - 1)\n",
    "                # print(\"reading bytes [%s,%s)...\" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "                buffer[idx:idx + batch_size] = self.f.read(batch_size)\n",
    "                # print(\"done.\", flush=True)\n",
    "                idx += batch_size\n",
    "            return buffer\n",
    "        return self.f.read(n)\n",
    "    def write(self, buffer):\n",
    "        n = len(buffer)\n",
    "        print(\"writing total_bytes=%s...\" % n, flush=True)\n",
    "        idx = 0\n",
    "        while idx < n:\n",
    "            batch_size = min(n - idx, 1 << 31 - 1)\n",
    "            print(\"writing bytes [%s, %s)... \" % (idx, idx + batch_size), end=\"\", flush=True)\n",
    "            self.f.write(buffer[idx:idx + batch_size])\n",
    "            print(\"done.\", flush=True)\n",
    "            idx += batch_size\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Initialize fsaverage brain with top 3 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 902629)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps = np.load('PCA/components.npz')['arr_0']\n",
    "comps = comps.transpose(0,3,2,1)\n",
    "comps.reshape(10,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def make_colorvol(proj, meanstds, rgbpcs, mask, flips=tuple(), clip_lim=3):\n",
    "    rgbdata = proj[rgbpcs,:]\n",
    "    for f in flips:\n",
    "        rgbdata[f] *= -1\n",
    "    zrgb = (rgbdata.T / meanstds).T\n",
    "    #zrgb = npp.rs(rgbdata.T).T\n",
    "    crgb = np.clip(zrgb, -clip_lim, clip_lim) ## clip to 3 standard deviations\n",
    "    srgb = crgb/clip_lim/2.0 + 0.5 ## scale to 0..1\n",
    "    \n",
    "    rgbvol = np.zeros([3]+list(mask.shape))\n",
    "    rgbvol[0] = vox_to_mask(srgb[0], mask)\n",
    "    rgbvol[1] = vox_to_mask(srgb[1], mask)\n",
    "    rgbvol[2] = vox_to_mask(srgb[2], mask)\n",
    "\n",
    "    colorvol = (rgbvol*255).astype(np.uint8)\n",
    "    return colorvol.transpose(1,2,3,0)\n",
    "\n",
    "def vox_to_mask(data, mask):\n",
    "    dvol = mask.copy().astype(np.float)\n",
    "    dvol[mask>0] = data\n",
    "    return dvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = lambda x: x/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_comps = comps.reshape(10,-1)\n",
    "\n",
    "colorvol = make_colorvol(flat_comps, flat_comps.std(1)[:3], [0,1,2], np.ones(comps[0].shape), clip_lim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbvol = cortex.dataset.normalize((colorvol, 'fsaverage', 'atlas_2mm'))\n",
    "rgbvol.alpha.vmin = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Package(rgbvol)\n",
    "png = list(p.images.values())[0][0]\n",
    "with open((\"rgbvol1.png\"),\"wb\") as f:\n",
    "    f.write(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# open new tab that displays the PCA brain\n",
    "cortex.webgl.show(data=rgbvol, template='my_template.html', labels_visible=(\"\"), overlays_visible=(\"\"), recache=True)\n",
    "\n",
    "## or create local server:\n",
    "# cortex.webgl.make_static(\"static\", data=rgbvol, template='my_template.html', labels_visible=(\"\"), overlays_visible=(\"\"), recache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create png for every neurosynth term to then project onto fsaverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/neurosynth/neurosynth if you encounter errors with Dataset\n",
    "dataset = Dataset('neurosynth-data/database.txt')\n",
    "dataset.add_features('neurosynth-data/features.txt')\n",
    "terms = pandas.read_csv('neurosynth-data/analysis_filter_list.tsv',delimiter='\\t')\n",
    "kept_terms = terms['term'][terms['keep']==1]\n",
    "np.savez(\"neurosynth_terms\",'kept_terms')\n",
    "for term in kept_terms:\n",
    "    ids = dataset.get_studies(term)\n",
    "    ma = meta.MetaAnalysis(dataset, ids)\n",
    "    maps[term] = ma.images['association-test_z']\n",
    "    ma.save_results(os.path.join('neurosynth-data','maps',term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(concat_maps.shape[0]):\n",
    "    \n",
    "    term = kept_terms.iloc[i];\n",
    "\n",
    "    p = Package(cortex.Volume((\"term_maps/\"+term+\".nii\"), subject, 'atlas_2mm'))\n",
    "\n",
    "    png = list(p.images.values())[0][0]\n",
    "\n",
    "    with open((\"neurosynth-maps/\"+term+\".png\"),\"wb\") as f:\n",
    "        f.write(png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associate terms with PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10724451 0.07186315 0.04695774 0.03718591 0.03011859 0.02566107\n",
      " 0.01888798 0.01386358 0.01315753 0.01177422]\n",
      "[7371.67572625 6034.36808339 4877.89306864 4340.78108748 3906.57327303\n",
      " 3605.9198214  3093.65168395 2650.43018478 2582.0570494  2442.55709004]\n"
     ]
    }
   ],
   "source": [
    "## note: concat_maps.p was too large to upload to GitHub, see PCA/PCA_extraction.ipynb to create concat_maps.p\n",
    "concat_maps = pickle_load(\"PCA/concat_maps.p\")\n",
    "ncomp = 10\n",
    "pca = PCA(copy=True, iterated_power='auto', n_components=ncomp, random_state=None,\n",
    "  svd_solver='randomized', tol=0.0, whiten=False).fit(concat_maps)\n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a list of all neurosynth terms\n",
    "terms = pandas.read_csv('PCA/analysis_filter_list.tsv',delimiter='\\t')\n",
    "# but we're only interested in the terms that are non-anatomical\n",
    "terms_anatfilter = pandas.read_csv('PCA/neurosynth_terms_anatfilter.txt',delimiter='\\t')\n",
    "\n",
    "# only keep terms that have a 'keep' value of 1 and n 'anatomical' value of 0\n",
    "kept_terms_anatfilter = terms_anatfilter['term'][np.logical_and(terms_anatfilter['keep']==1, terms_anatfilter['anatomical']==0)]\n",
    "# we will take these terms and find their location in a list that is ordered alphabetically\n",
    "kept_terms = terms['term'][terms['keep']==1]\n",
    "anatfilter_indices = [i for i,k in enumerate(list(kept_terms)) if k in list(kept_terms_anatfilter)]\n",
    "kept_terms_anatfilter = kept_terms.iloc[anatfilter_indices]\n",
    "\n",
    "concat_maps_anatfilter = concat_maps[anatfilter_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see PCA/PCA_extraction.ipynb to create components.npz\n",
    "components = np.load(\"PCA/components.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PCA component png maps\n",
    "for i in range(10):\n",
    "    p = Package(cortex.Volume((components[i,:,:,:].T/np.std(components[i,:,:,:].T)), subject, 'atlas_2mm'))\n",
    "\n",
    "    png = list(p.images.values())[0][0]\n",
    "\n",
    "    with open((\"neurosynth-maps/pca\"+str(i+1)+\".png\"),\"wb\") as f:\n",
    "        f.write(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_weights = pca.transform(concat_maps_anatfilter)\n",
    "# term_weights = np.load(\"PCA/term_weights.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "motor\n",
      "1317.6320905494947\n",
      "movements\n",
      "1082.6326032578986\n",
      "movement\n",
      "900.2029858276059\n",
      "hand\n",
      "887.2103314241627\n",
      "finger\n",
      "861.8239098596807\n",
      "\n",
      "\n",
      "emotional\n",
      "-608.1144302905019\n",
      "negative\n",
      "-514.7500530933149\n",
      "reward\n",
      "-500.44840115901064\n",
      "social\n",
      "-465.58541684155347\n",
      "neutral\n",
      "-448.30683321309544\n",
      "\n",
      " 1\n",
      "semantic\n",
      "633.6148278818989\n",
      "language\n",
      "629.3179671445515\n",
      "words\n",
      "615.9370102630622\n",
      "visual\n",
      "603.6445620059216\n",
      "word\n",
      "595.8302894672337\n",
      "\n",
      "\n",
      "pain\n",
      "-605.0312709266811\n",
      "motor\n",
      "-578.627686885328\n",
      "reward\n",
      "-496.6405797600661\n",
      "finger\n",
      "-444.48396863699276\n",
      "movement\n",
      "-434.6616056838099\n",
      "\n",
      " 2\n",
      "auditory\n",
      "813.2986946934237\n",
      "speech\n",
      "679.4845842781803\n",
      "sounds\n",
      "590.4998321348987\n",
      "listening\n",
      "517.4453533388773\n",
      "acoustic\n",
      "465.6533403985085\n",
      "\n",
      "\n",
      "memory\n",
      "-623.8525727947683\n",
      "task\n",
      "-589.5702800580941\n",
      "retrieval\n",
      "-466.03949697898537\n",
      "working memory\n",
      "-452.0013094077859\n",
      "working\n",
      "-448.10586096960776\n",
      "\n",
      " 3\n",
      "visual\n",
      "383.39499851662646\n",
      "motion\n",
      "356.8537640756567\n",
      "object\n",
      "310.57966394226366\n",
      "spatial\n",
      "282.95892195528666\n",
      "faces\n",
      "277.5914854709835\n",
      "\n",
      "\n",
      "auditory\n",
      "-413.6016425246062\n",
      "semantic\n",
      "-404.197738839632\n",
      "autobiographical\n",
      "-393.7733859841438\n",
      "pain\n",
      "-385.71087291112326\n",
      "speech\n",
      "-384.812455373418\n",
      "\n",
      " 4\n",
      "faces\n",
      "478.52015000591484\n",
      "face\n",
      "460.51339671130097\n",
      "visual\n",
      "436.6199080615679\n",
      "objects\n",
      "330.6010851849625\n",
      "viewing\n",
      "316.8168399167933\n",
      "\n",
      "\n",
      "working memory\n",
      "-313.9826256638254\n",
      "working\n",
      "-303.39719926417365\n",
      "auditory\n",
      "-300.27890126450734\n",
      "cognitive control\n",
      "-272.4012834892174\n",
      "speech\n",
      "-267.6659570774664\n",
      "\n",
      " 5\n",
      "default\n",
      "593.8154391962797\n",
      "default mode\n",
      "548.2583082756481\n",
      "resting\n",
      "547.4276360171302\n",
      "resting state\n",
      "543.6450118482949\n",
      "dmn\n",
      "463.3240607057509\n",
      "\n",
      "\n",
      "reward\n",
      "-434.0223487809583\n",
      "face\n",
      "-293.6580430131016\n",
      "monetary\n",
      "-292.1518800709242\n",
      "faces\n",
      "-284.24350319222594\n",
      "anticipation\n",
      "-271.10199059070413\n",
      "\n",
      " 6\n",
      "memory\n",
      "341.1205471126759\n",
      "vermis\n",
      "266.7269991772766\n",
      "verbal\n",
      "228.14698843890486\n",
      "encoding\n",
      "226.8165239253406\n",
      "episodic memory\n",
      "210.8756965029162\n",
      "\n",
      "\n",
      "social\n",
      "-395.532515189582\n",
      "theory mind\n",
      "-312.6339580970791\n",
      "mentalizing\n",
      "-279.9374815202056\n",
      "mind tom\n",
      "-264.7374893152945\n",
      "action\n",
      "-262.94513314463944\n",
      "\n",
      " 7\n",
      "auditory\n",
      "489.2366182480341\n",
      "sounds\n",
      "328.5186070718906\n",
      "listening\n",
      "253.45694512758487\n",
      "acoustic\n",
      "249.67204663367062\n",
      "spatial\n",
      "249.3677122127114\n",
      "\n",
      "\n",
      "word\n",
      "-260.29879844716976\n",
      "reading\n",
      "-252.22496129356622\n",
      "semantic\n",
      "-242.12539619724913\n",
      "words\n",
      "-240.11917929241028\n",
      "language\n",
      "-215.61293671677373\n",
      "\n",
      " 8\n",
      "reward\n",
      "388.64235479093276\n",
      "monetary\n",
      "320.3683071901248\n",
      "incentive\n",
      "255.61093147870727\n",
      "incentive delay\n",
      "245.14859448458336\n",
      "monetary incentive\n",
      "230.2045819443251\n",
      "\n",
      "\n",
      "pain\n",
      "-423.28359380317477\n",
      "painful\n",
      "-345.9629292203722\n",
      "noxious\n",
      "-294.9394356883543\n",
      "nociceptive\n",
      "-265.46982209535264\n",
      "stimulation\n",
      "-247.34939085330623\n",
      "\n",
      " 9\n",
      "vermis\n",
      "472.7565515714943\n",
      "conditioning\n",
      "205.53381418809528\n",
      "verbal working\n",
      "176.99256325889397\n",
      "cognitive task\n",
      "159.20618102967236\n",
      "conditioned\n",
      "153.83545558160202\n",
      "\n",
      "\n",
      "retrieval\n",
      "-201.14059509593147\n",
      "episodic\n",
      "-170.19573811323116\n",
      "finger\n",
      "-148.4128196028129\n",
      "episodic memory\n",
      "-146.873884807954\n",
      "recollection\n",
      "-144.28068434829945\n"
     ]
    }
   ],
   "source": [
    "for i in range(ncomp):\n",
    "    a = term_weights[:,i].argsort()[::-1];\n",
    "    print('\\n',i);\n",
    "    for j in range(5):\n",
    "        print(kept_terms_anatfilter.iloc[a[j]]);\n",
    "        print(term_weights[a[j],i]);\n",
    "    print('\\n')\n",
    "    for k in range(5):\n",
    "        print(kept_terms_anatfilter.iloc[a[-(k+1)]]);\n",
    "        print(term_weights[a[-(k+1)],i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wordclouds\n",
    "first_three = term_weights[:,0:2]\n",
    "for i in range(3):\n",
    "\n",
    "    hull = spatial.ConvexHull(term_weights[:, i*3:(i+1)*3])\n",
    "    vertices = first_three[hull.vertices,:]\n",
    "\n",
    "    pca = PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
    "      svd_solver='randomized', tol=0.0, whiten=False).fit(vertices)\n",
    "    twod_projection = pca.transform(vertices)\n",
    "    twod_projection\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 0.99))\n",
    "    scaler = scaler.fit(term_weights[:, i*3:(i+1)*3])\n",
    "    colors = scaler.transform(term_weights[hull.vertices, i*3:(i+1)*3])\n",
    "    colors = colors+.3 # make colors a bit brighter so it can be read on black bg\n",
    "    colors[colors>1] = 1\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # twod_projection[:,0].shape\n",
    "    ax.scatter(twod_projection[:,0], twod_projection[:,1], c='black')\n",
    "\n",
    "    # fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    for j in range(twod_projection.shape[0]):\n",
    "        ax.text(twod_projection[j,0],twod_projection[j,1],kept_terms_anatfilter.iloc[hull.vertices[j]], color = colors[j,:], fontweight='bold')\n",
    "\n",
    "    plt.savefig('PCA/wordCloud%d_anatfilter.png'%(i+1), format='png', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show anatomical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Glasser atlas\n",
    "lh_aparc_file = os.path.join('atlases','lh.HCP-MMP1.annot')\n",
    "rh_aparc_file = os.path.join('atlases','rh.HCP-MMP1.annot')\n",
    "lpinds, lpstats, lpnames = nib.freesurfer.read_annot(lh_aparc_file)\n",
    "lpinds_orig, lpstats, lpnames = nib.freesurfer.read_annot(lh_aparc_file, True)\n",
    "lpinds[lpinds_orig==0] = -1\n",
    "rpinds, rpstats, rpnames = nib.freesurfer.read_annot(rh_aparc_file)\n",
    "rpinds_orig, rpstats, rpnames = nib.freesurfer.read_annot(rh_aparc_file, True)\n",
    "rpinds[rpinds_orig==0] = -1\n",
    "\n",
    "aparc = cortex.Vertex(np.hstack([lpinds, rpinds]),'fsaverage')\n",
    "\n",
    "## open new tab to display brain:\n",
    "# cortex.webgl.show(data=rgbvol, template='my_template.html', overlays_visible=(\"rois\"), recache=True)\n",
    "\n",
    "## or create local server:\n",
    "cortex.webgl.make_static(\"static\", data=rgbvol, template='my_template.html', labels_visible=(\"\"), overlays_visible=(\"rois\"), recache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "° You will need to have your functional map .pngs located in the data folder in your static local server for the functional maps for every term to be displayed on the brain correctly. If the path is not accessible, you may also need to edit the code of the index.html file inside the same folder to ensure that your server has access to your local files.\n",
    "\n",
    "° There are some changes in the index.html file on github.com/PaulScotti/educortex that add a few additional features, such as a welcome pop-up window, making the top-left panel non-clickable, etc. You can copy this index.html file and modify it to your own use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}