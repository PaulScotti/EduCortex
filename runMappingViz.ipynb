{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from neurosynth import meta, decode, network, Dataset\n",
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from nilearn import plotting\n",
    "import nilearn\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"dataset.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('neurosynth-data/database.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/neurosynth/base/dataset.py:624: FutureWarning: DataFrame/Series.to_dense is deprecated and will be removed in a future version\n",
      "  old_data = self.data.to_dense()\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/neurosynth/base/dataset.py:634: FutureWarning: DataFrame.to_sparse is deprecated and will be removed in a future version\n",
      "  self.data = data.fillna(0.0).to_sparse()\n"
     ]
    }
   ],
   "source": [
    "dataset.add_features('neurosynth-data/features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = pandas.read_csv('neurosynth-data/analysis_filter_list.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_terms = terms['term'][terms['keep']==1]\n",
    "np.savez(\"neurosynth_terms\",'kept_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/neurosynth/base/dataset.py:716: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  feature_weights = self.data.ix[:, features]\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/indexing.py:808: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/frame.py:3451: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/sparse/frame.py:785: FutureWarning: SparseDataFrame is deprecated and will be removed in a future version.\n",
      "Use a regular DataFrame whose columns are SparseArrays instead.\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(new_arrays, index=index, columns=columns).__finalize__(\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/apply.py:401: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  for i, (arr, name) in enumerate(zip(self.values, self.index))\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/apply.py:345: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  result = self.obj._constructor_sliced(results)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1641: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(new_values, index=self.index, name=self.name)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/sparse/series.py:585: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(arr, index=self.index).__finalize__(self)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/sparse/series.py:346: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  self._data.get_slice(indexer), fastpath=True\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/neurosynth/analysis/meta.py:134: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pFgA = pAgF * pF / pA\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/neurosynth/analysis/meta.py:139: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pFgA_prior = pAgF * prior / pAgF_prior\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/neurosynth/base/dataset.py:716: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  feature_weights = self.data.ix[:, features]\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/indexing.py:808: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/frame.py:3451: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return klass(values, index=self.index, name=items, fastpath=True)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/sparse/frame.py:785: FutureWarning: SparseDataFrame is deprecated and will be removed in a future version.\n",
      "Use a regular DataFrame whose columns are SparseArrays instead.\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(new_arrays, index=index, columns=columns).__finalize__(\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/apply.py:401: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  for i, (arr, name) in enumerate(zip(self.values, self.index))\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/apply.py:345: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  result = self.obj._constructor_sliced(results)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1641: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(new_values, index=self.index, name=self.name)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/sparse/series.py:585: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  return self._constructor(arr, index=self.index).__finalize__(self)\n",
      "/Users/scotti.5/Documents/GitHub/pycortex/env/lib/python3.6/site-packages/pandas/core/sparse/series.py:346: FutureWarning: SparseSeries is deprecated and will be removed in a future version.\n",
      "Use a Series with sparse values instead.\n",
      "\n",
      "    >>> series = pd.Series(pd.SparseArray(...))\n",
      "\n",
      "See http://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating for more.\n",
      "\n",
      "  self._data.get_slice(indexer), fastpath=True\n"
     ]
    }
   ],
   "source": [
    "for term in kept_terms:\n",
    "    ids = dataset.get_studies(term)\n",
    "    ma = meta.MetaAnalysis(dataset, ids)\n",
    "    maps[term] = ma.images['association-test_z']\n",
    "    ma.save_results(os.path.join('neurosynth-data','maps',term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle concat_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def try_to_load_as_pickled_object_or_None(filepath):\n",
    "    \"\"\"\n",
    "    This is a defensive way to write pickle.load, allowing for very large files on all platforms\n",
    "    \"\"\"\n",
    "    max_bytes = 2**31 - 1\n",
    "    try:\n",
    "        input_size = os.path.getsize(filepath)\n",
    "        bytes_in = bytearray(0)\n",
    "        with open(filepath, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        obj = pickle.loads(bytes_in)\n",
    "    except:\n",
    "        return None\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_maps = try_to_load_as_pickled_object_or_None(\"concat_maps.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(concat_maps.shape[0]):\n",
    "    term = kept_terms.iloc[i];\n",
    "    img = nilearn.image.new_img_like(dataset.masker.volume, dataset.masker.unmask(concat_maps[i],'array'))\n",
    "    nib.save(img, os.path.join('term_maps',term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cortex\n",
    "subject = 'fsaverage'\n",
    "anat = cortex.db.get_anat(subject, 'raw')\n",
    "anat_data = anat.get_data()\n",
    "anat_vol = cortex.Volume.empty(subject, 'atlas_2mm')\n",
    "\n",
    "# cortex.webgl.show(data=anat_vol, template='my_template.html', recache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex.webgl.data import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for i in range(concat_maps.shape[0]):\n",
    "    \n",
    "    term = kept_terms.iloc[i];\n",
    "\n",
    "    p = Package(cortex.Volume((\"term_maps/\"+term+\".nii\"), subject, 'atlas_2mm'))\n",
    "\n",
    "    png = list(p.images.values())[0][0]\n",
    "\n",
    "    with open((\"neurosynth-maps/\"+term+\".png\"),\"wb\") as f:\n",
    "        f.write(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    p = Package(cortex.Volume((components[i,:,:,:].T/np.std(components[i,:,:,:].T)), subject, 'atlas_2mm'))\n",
    "\n",
    "    png = list(p.images.values())[0][0]\n",
    "\n",
    "    with open((\"neurosynth-maps/pca\"+str(i+1)+\".png\"),\"wb\") as f:\n",
    "        f.write(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Package(rgbvol)\n",
    "\n",
    "png = list(p.images.values())[0][0]\n",
    "\n",
    "with open((\"rgbvol3.png\"),\"wb\") as f:\n",
    "    f.write(png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 902629)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps = np.load('data/components.npz')['arr_0']\n",
    "comps = comps.transpose(0,3,2,1)\n",
    "comps.reshape(10,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def make_colorvol(proj, meanstds, rgbpcs, mask, flips=tuple(), clip_lim=3):\n",
    "    rgbdata = proj[rgbpcs,:]\n",
    "    for f in flips:\n",
    "        rgbdata[f] *= -1\n",
    "    zrgb = (rgbdata.T / meanstds).T\n",
    "    #zrgb = npp.rs(rgbdata.T).T\n",
    "    crgb = np.clip(zrgb, -clip_lim, clip_lim) ## clip to 3 standard deviations\n",
    "    srgb = crgb/clip_lim/2.0 + 0.5 ## scale to 0..1\n",
    "    \n",
    "    rgbvol = np.zeros([3]+list(mask.shape))\n",
    "    rgbvol[0] = vox_to_mask(srgb[0], mask)\n",
    "    rgbvol[1] = vox_to_mask(srgb[1], mask)\n",
    "    rgbvol[2] = vox_to_mask(srgb[2], mask)\n",
    "\n",
    "    colorvol = (rgbvol*255).astype(np.uint8)\n",
    "    return colorvol.transpose(1,2,3,0)\n",
    "\n",
    "def vox_to_mask(data, mask):\n",
    "    dvol = mask.copy().astype(np.float)\n",
    "    dvol[mask>0] = data\n",
    "    return dvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = lambda x: x/x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_comps = comps.reshape(10,-1)\n",
    "\n",
    "colorvol = make_colorvol(flat_comps, flat_comps.std(1)[:3], [0,1,2], np.ones(comps[0].shape), clip_lim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbvol = cortex.dataset.normalize((colorvol, 'fsaverage', 'atlas_2mm'))\n",
    "rgbvol.alpha.vmin = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new ctm file...\n",
      "wm\n",
      "wm\n",
      "inflated\n",
      "inflated\n"
     ]
    }
   ],
   "source": [
    "# cortex.webgl.show(data=rgbvol, template='my_template.html', recache=True)\n",
    "cortex.webgl.make_static(\"static\",data=rgbvol, template='my_template.html', with_labels=False, recache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individual PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10724451 0.07186315 0.04695774 0.03718591 0.03011859 0.02566107\n",
      " 0.01888798 0.01386358 0.01315753 0.01177422]\n",
      "[7371.67572625 6034.36808339 4877.89306864 4340.78108748 3906.57327303\n",
      " 3605.9198214  3093.65168397 2650.43018536 2582.05702134 2442.55708149]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
    "  svd_solver='randomized', tol=0.0, whiten=False).fit(concat_maps)\n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "components = np.array([dataset.masker.unmask(pca.components_[i],output='array') for i in range(10)])\n",
    "np.savez('components',components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x13b5486d8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = np.load(\"components.npz\")\n",
    "components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_weights = pca.transform(concat_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motor' 'premotor' 'movements' 'movement' 'hand' 'medial' 'hippocampus'\n",
      " 'medial prefrontal' 'emotional' 'amygdala']\n",
      "0\n",
      "['temporal' 'semantic' 'language' 'words' 'visual' 'striatum' 'insula'\n",
      " 'somatosensory' 'motor' 'pain']\n",
      "1\n",
      "['auditory' 'superior temporal' 'speech' 'auditory cortex' 'sounds'\n",
      " 'retrieval' 'task' 'prefrontal' 'memory' 'parietal']\n",
      "2\n",
      "['occipital' 'lateral occipital' 'visual' 'motion' 'intraparietal'\n",
      " 'autobiographical' 'semantic' 'insula' 'auditory' 'temporal']\n",
      "3\n",
      "['hippocampus' 'amygdala' 'fusiform' 'faces' 'medial temporal'\n",
      " 'inferior frontal' 'frontal gyrus' 'working memory' 'dorsolateral'\n",
      " 'frontal']\n",
      "4\n",
      "['default' 'default mode' 'resting' 'resting state' 'dmn' 'nucleus'\n",
      " 'insula' 'amygdala' 'striatum' 'reward']\n",
      "5\n",
      "['cerebellar' 'vi' 'cerebellum' 'hippocampal' 'hippocampus' 'insula'\n",
      " 'medial prefrontal' 'junction' 'theory mind' 'social']\n",
      "6\n",
      "['auditory' 'auditory cortex' 'sounds' 'planum' 'planum temporale'\n",
      " 'inferior frontal' 'words' 'semantic' 'reading' 'word']\n",
      "7\n",
      "['striatum' 'reward' 'ventral striatum' 'monetary' 'striatal'\n",
      " 'secondary somatosensory' 'somatosensory' 'painful' 'insula' 'pain']\n",
      "8\n",
      "['vi' 'cerebellar' 'cerebellum' 'lobules' 'vermis' 'retrieval' 'mtl'\n",
      " 'primary motor' 'hippocampal' 'hippocampus']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    a = term_weights[:,i].argsort()[::-1];\n",
    "    print(np.concatenate((kept_terms.iloc[a[:5]], kept_terms.iloc[a[-5:]]), axis=None));\n",
    "    print(i);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new ctm file...\n",
      "wm\n",
      "wm\n",
      "inflated\n",
      "inflated\n",
      "Started server on port 9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<JS: window.viewer>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load glasser atlas\n",
    "lh_aparc_file = os.path.join('atlases','lh.HCP-MMP1.annot')\n",
    "rh_aparc_file = os.path.join('atlases','rh.HCP-MMP1.annot')\n",
    "lpinds, lpstats, lpnames = nib.freesurfer.read_annot(lh_aparc_file)\n",
    "lpinds_orig, lpstats, lpnames = nib.freesurfer.read_annot(lh_aparc_file, True)\n",
    "lpinds[lpinds_orig==0] = -1\n",
    "rpinds, rpstats, rpnames = nib.freesurfer.read_annot(rh_aparc_file)\n",
    "rpinds_orig, rpstats, rpnames = nib.freesurfer.read_annot(rh_aparc_file, True)\n",
    "rpinds[rpinds_orig==0] = -1\n",
    "\n",
    "aparc = cortex.Vertex(np.hstack([lpinds, rpinds]),'fsaverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 54,  49,  41, ..., 135, 135, 135], dtype=int32)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([lpinds, rpinds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
